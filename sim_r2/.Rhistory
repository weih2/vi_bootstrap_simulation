(beta.posterior$phi < 1 - prob.threshold))
if(sum(active.set) == 0) break
# inv.A = update.A(inv.A, active.set, B, D)
# inv.A = update.A(beta.posterior)
new_entropy = cal.entropy(beta.posterior$phi, active.set)
if(max(abs(new_entropy - entropy)) < epsilon) break
print(
list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
)
)
}
return(list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
))
}
main.loop()
# main loop
main.loop = function(o){
beta.posterior = init.beta.posterior()
global.posterior = init.global.posterior()
new_entropy = rep(0, n.pars)
active.set = rep(TRUE, n.pars)
inv.A = solve(
XTX %*% diag(beta.posterior$phi) + diag(n.pars)/nu1
)
D = numeric(n.pars)
B = XTX - diagXTX
repeat{
entropy = new_entropy
D = - (beta.posterior$phi)
beta.posterior = cavi.estimate(beta.posterior, global.posterior, inv.A, active.set)
global.posterior = em.estimate(beta.posterior, global.posterior)
D = D + (beta.posterior$phi)
# exclude probabilities close to 0 or 1 from iteration
active.set = ((beta.posterior$phi > prob.threshold) &
(beta.posterior$phi < 1 - prob.threshold))
if(sum(active.set) == 0) break
inv.A = update.A(inv.A, active.set, B, D)
new_entropy = cal.entropy(beta.posterior$phi, active.set)
if(max(abs(new_entropy - entropy)) < epsilon) break
print(
list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
)
)
}
return(list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
))
}
main.loop()
update.A = function(inv.A, active.set, B, D){
inv.A = inv.A - inv.A %*% B[, active.set] %*%
solve(diag(1/D[active.set]) + inv.A[active.set, ] %*% B[, active.set]) %*%
inv.A[active.set, ]
return(inv.A)
}
main.loop()
auto.cor = 0.01 # collinearity
data = gen.everything()
XTX = t(data$X) %*% (data$X)
diagXTX = diag(XTX)
XTy = t(data$X) %*% (data$y)
main.loop()
auto.cor = 0.00 # collinearity
data = gen.everything()
XTX = t(data$X) %*% (data$X)
diagXTX = diag(XTX)
XTy = t(data$X) %*% (data$y)
warings()
warnings()
data = gen.everything()
auto.cor = 0.001 # collinearity
# generate one observation
gen.one.obs = function(o){
as.numeric(
arima.sim(
list(c(1,0,0), # ar(1) model
ar = auto.cor),
n = n.pars
)
)
}
# generate all observations
gen.all.obs = function(o){
sapply(1:n.obs, gen.one.obs)
}
# arrange all observations
create.design.matrix = function(o){
t(gen.all.obs())
}
# generate y, put x and y into the same object
gen.everything = function(){
X = create.design.matrix()
noise = rnorm(n.obs, sd = sqrt(sigma2))
y = X %*% beta + noise
return(list(X = X, y = y))
}
data = gen.everything()
XTX = t(data$X) %*% (data$X)
diagXTX = diag(XTX)
XTy = t(data$X) %*% (data$y)
main.loop()
# generate one observation
gen.one.obs = function(o){
if(auto.cor != 0)
as.numeric(
arima.sim(
list(c(1,0,0), # ar(1) model
ar = auto.cor),
n = n.pars
)
)else
rnorm(n.pars)
}
auto.cor = 0.00 # collinearity
data = gen.everything()
XTX = t(data$X) %*% (data$X)
diagXTX = diag(XTX)
XTy = t(data$X) %*% (data$y)
main.loop()
update.A.slow = function(beta.posterior){
return(
solve(
XTX %*% diag(beta.posterior$phi) + diag(diagXTX * (1 - beta.posterior$phi)) +
diag(n.pars)/nu1
)
)
}
# main loop
main.loop = function(o){
beta.posterior = init.beta.posterior()
global.posterior = init.global.posterior()
new_entropy = rep(0, n.pars)
active.set = rep(TRUE, n.pars)
inv.A = solve(
XTX %*% diag(beta.posterior$phi) + diag(n.pars)/nu1
)
D = numeric(n.pars)
B = XTX - diagXTX
repeat{
entropy = new_entropy
D = - (beta.posterior$phi)
beta.posterior = cavi.estimate(beta.posterior, global.posterior, inv.A, active.set)
global.posterior = em.estimate(beta.posterior, global.posterior)
D = D + (beta.posterior$phi)
# exclude probabilities close to 0 or 1 from iteration
active.set = ((beta.posterior$phi > prob.threshold) &
(beta.posterior$phi < 1 - prob.threshold))
if(sum(active.set) == 0) break
inv.A = update.A(inv.A, active.set, B, D)
print(inv.A)
print(update.A.slow(beta.posterior))
new_entropy = cal.entropy(beta.posterior$phi, active.set)
if(max(abs(new_entropy - entropy)) < epsilon) break
print(
list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
)
)
}
return(list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
))
}
main.loop()
# main loop
main.loop = function(o){
beta.posterior = init.beta.posterior()
global.posterior = init.global.posterior()
new_entropy = rep(0, n.pars)
active.set = rep(TRUE, n.pars)
inv.A = solve(
XTX %*% diag(beta.posterior$phi) + diag(n.pars)/nu1
)
D = numeric(n.pars)
B = XTX - diagXTX
repeat{
entropy = new_entropy
D = - (beta.posterior$phi)
beta.posterior = cavi.estimate(beta.posterior, global.posterior, inv.A, active.set)
global.posterior = em.estimate(beta.posterior, global.posterior)
D = D + (beta.posterior$phi)
# exclude probabilities close to 0 or 1 from iteration
active.set = ((beta.posterior$phi > prob.threshold) &
(beta.posterior$phi < 1 - prob.threshold))
if(sum(active.set) == 0) break
inv.A = update.A(inv.A, active.set, B, D)
inv.A = update.A.slow(beta.posterior)
print(inv.A)
print(update.A.slow(beta.posterior))
new_entropy = cal.entropy(beta.posterior$phi, active.set)
if(max(abs(new_entropy - entropy)) < epsilon) break
print(
list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
)
)
}
return(list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
))
}
main.loop()
# main loop
main.loop = function(o){
beta.posterior = init.beta.posterior()
global.posterior = init.global.posterior()
new_entropy = rep(0, n.pars)
active.set = rep(TRUE, n.pars)
inv.A = solve(
XTX %*% diag(beta.posterior$phi) + diag(n.pars)/nu1
)
D = numeric(n.pars)
B = XTX - diag(diagXTX)
repeat{
entropy = new_entropy
D = - (beta.posterior$phi)
beta.posterior = cavi.estimate(beta.posterior, global.posterior, inv.A, active.set)
global.posterior = em.estimate(beta.posterior, global.posterior)
D = D + (beta.posterior$phi)
# exclude probabilities close to 0 or 1 from iteration
active.set = ((beta.posterior$phi > prob.threshold) &
(beta.posterior$phi < 1 - prob.threshold))
if(sum(active.set) == 0) break
inv.A = update.A(inv.A, active.set, B, D)
inv.A = update.A.slow(beta.posterior)
print(inv.A)
print(update.A.slow(beta.posterior))
new_entropy = cal.entropy(beta.posterior$phi, active.set)
if(max(abs(new_entropy - entropy)) < epsilon) break
print(
list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
)
)
}
return(list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
))
}
main.loop()
# main loop
main.loop = function(o){
beta.posterior = init.beta.posterior()
global.posterior = init.global.posterior()
new_entropy = rep(0, n.pars)
active.set = rep(TRUE, n.pars)
inv.A = solve(
XTX %*% diag(beta.posterior$phi) + diag(n.pars)/nu1
)
D = numeric(n.pars)
B = XTX - diag(diagXTX)
repeat{
entropy = new_entropy
D = - (beta.posterior$phi)
beta.posterior = cavi.estimate(beta.posterior, global.posterior, inv.A, active.set)
global.posterior = em.estimate(beta.posterior, global.posterior)
D = D + (beta.posterior$phi)
# exclude probabilities close to 0 or 1 from iteration
active.set = ((beta.posterior$phi > prob.threshold) &
(beta.posterior$phi < 1 - prob.threshold))
if(sum(active.set) == 0) break
inv.A = update.A(inv.A, active.set, B, D)
new_entropy = cal.entropy(beta.posterior$phi, active.set)
if(max(abs(new_entropy - entropy)) < epsilon) break
print(
list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
)
)
}
return(list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
))
}
main.loop
main.loop()
# main loop
main.loop = function(o){
beta.posterior = init.beta.posterior()
global.posterior = init.global.posterior()
new_entropy = rep(0, n.pars)
active.set = rep(TRUE, n.pars)
inv.A = solve(
XTX %*% diag(beta.posterior$phi) + diag(n.pars)/nu1
)
D = numeric(n.pars)
B = XTX - diag(diagXTX)
repeat{
entropy = new_entropy
D = - (beta.posterior$phi)
beta.posterior = cavi.estimate(beta.posterior, global.posterior, inv.A, active.set)
global.posterior = em.estimate(beta.posterior, global.posterior)
D = D + (beta.posterior$phi)
# exclude probabilities close to 0 or 1 from iteration
active.set = ((beta.posterior$phi > prob.threshold) &
(beta.posterior$phi < 1 - prob.threshold))
if(sum(active.set) == 0) break
inv.A = update.A(inv.A, active.set, B, D)
new_entropy = cal.entropy(beta.posterior$phi, active.set)
if(max(abs(new_entropy - entropy)) < epsilon) break
}
return(list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
))
}
main.loop()
source("point_estimate.R")
main.loop()
gen.weights = function(o){
weights = rexp(n.obs)
weights = weights/sum(weights) * n.obs
return(weights)
}
for(i in 1:n.b.samples){
weights = gen.weights()
data.X = diag(sqrt(weights)) %*% orignal.data$X
data.y = diag(sqrt(weights)) %*% orignal.data$y
XTX = t(original.data$X) %*% diag(weights) %*% original.data$X
diagXTX = diag(XTX)
XTy = t(original.data$X) %*% diag(weights) %*% original.data$y
beta1.bootstrap.map = c(beta1.bootstrap.map,
main.loop()$beta.posterior$mu[1]
)
}
n.b.samples = 100
original.data = data
beta1.bootstrap.map = numeric(0)
for(i in 1:n.b.samples){
weights = gen.weights()
data.X = diag(sqrt(weights)) %*% orignal.data$X
data.y = diag(sqrt(weights)) %*% orignal.data$y
XTX = t(original.data$X) %*% diag(weights) %*% original.data$X
diagXTX = diag(XTX)
XTy = t(original.data$X) %*% diag(weights) %*% original.data$y
beta1.bootstrap.map = c(beta1.bootstrap.map,
main.loop()$beta.posterior$mu[1]
)
}
for(i in 1:n.b.samples){
weights = gen.weights()
data.X = diag(sqrt(weights)) %*% original.data$X
data.y = diag(sqrt(weights)) %*% original.data$y
XTX = t(original.data$X) %*% diag(weights) %*% original.data$X
diagXTX = diag(XTX)
XTy = t(original.data$X) %*% diag(weights) %*% original.data$y
beta1.bootstrap.map = c(beta1.bootstrap.map,
main.loop()$beta.posterior$mu[1]
)
}
beta1.bootstrap.map
n.pars = 10 # no. covariates
beta = c(2, 3, rep(0, n.pars - 2)) # true beta
data = gen.everything()
XTX = t(data$X) %*% (data$X)
diagXTX = diag(XTX)
XTy = t(data$X) %*% (data$y)
original.data = data
beta1.bootstrap.map = numeric(0)
for(i in 1:n.b.samples){
weights = gen.weights()
data.X = diag(sqrt(weights)) %*% original.data$X
data.y = diag(sqrt(weights)) %*% original.data$y
XTX = t(original.data$X) %*% diag(weights) %*% original.data$X
diagXTX = diag(XTX)
XTy = t(original.data$X) %*% diag(weights) %*% original.data$y
beta1.bootstrap.map = c(beta1.bootstrap.map,
main.loop()$beta.posterior$mu[1]
)
}
hist(beta1.bootstrap.map)
quantile(0.1, c(1,2,3,4,5,6,7,8,9))
help(quantile)
quantile(c(1,2,3,4,5,6,7,8,9), 0.1)
str(quantile(c(1,2,3,4,5,6,7,8,9), 0.1))
source("point_estimate.R")
n.experiments = 100
n.b.samples = 500
original.data = data
get.beta1.vwlb.cs = function(confidence){
beta1.bootstrap.map = numeric(0)
for(i in 1:n.b.samples){
weights = gen.weights()
data.X = diag(sqrt(weights)) %*% original.data$X
data.y = diag(sqrt(weights)) %*% original.data$y
XTX = t(original.data$X) %*% diag(weights) %*% original.data$X
diagXTX = diag(XTX)
XTy = t(original.data$X) %*% diag(weights) %*% original.data$y
beta1.bootstrap.map = c(beta1.bootstrap.map,
main.loop()$beta.posterior$mu[1])
}
return( c(
quantile(beta1.bootstrap.map, (1 - confidence)/2),
quantile(beta1.bootstrap.map, (1 + confidence)/2)
))
}
for(i in 1:n.experiments){
covered = 0
vwlb.cs = get.beta1.vwlb.cs()
if(
(vwlb.cs[1] < beta[1])&
(vwlb.cs[2] > beta[2])
) covered = covered + 1
}
for(i in 1:n.experiments){
covered = 0
vwlb.cs = get.beta1.vwlb.cs(0.95)
if(
(vwlb.cs[1] < beta[1])&
(vwlb.cs[2] > beta[2])
) covered = covered + 1
}
covered = 0
covered = 0
for(i in 1:n.experiments){
if(i % 10 == 0) print(i)
vwlb.cs = get.beta1.vwlb.cs(0.95)
if(
(vwlb.cs[1] < beta[1])&
(vwlb.cs[2] > beta[1])
) covered = covered + 1
}
10 % 4
10 %% 4
for(i in 1:n.experiments){
if(i %% 10 == 0) print(i)
vwlb.cs = get.beta1.vwlb.cs(0.95)
if(
(vwlb.cs[1] < beta[1])&
(vwlb.cs[2] > beta[1])
) covered = covered + 1
}
for(i in 1:n.experiments){
if(i %% 10 == 0) print(i)
vwlb.cs = get.beta1.vwlb.cs(0.95)
print(vwlb.cs)
if(
(vwlb.cs[1] < beta[1])&
(vwlb.cs[2] > beta[1])
) covered = covered + 1
}
get.beta1.vwlb.cs(0.95)
get.beta1.vwlb.cs = function(confidence){
beta1.bootstrap.map = numeric(0)
for(i in 1:n.b.samples){
weights = gen.weights()
data.X <<- diag(sqrt(weights)) %*% original.data$X
data.y <<- diag(sqrt(weights)) %*% original.data$y
XTX <<- t(original.data$X) %*% diag(weights) %*% original.data$X
diagXTX <<- diag(XTX)
XTy <<- t(original.data$X) %*% diag(weights) %*% original.data$y
beta1.bootstrap.map = c(beta1.bootstrap.map,
main.loop()$beta.posterior$mu[1])
}
return( c(
quantile(beta1.bootstrap.map, (1 - confidence)/2),
quantile(beta1.bootstrap.map, (1 + confidence)/2)
))
}
get.beta1.vwlb.cs(0.95)
get.beta1.vwlb.cs = function(confidence){
beta1.bootstrap.map = numeric(0)
for(i in 1:n.b.samples){
weights = gen.weights()
data.X <<- diag(sqrt(weights)) %*% original.data$X
data.y <<- diag(sqrt(weights)) %*% original.data$y
XTX <<- t(original.data$X) %*% diag(weights) %*% original.data$X
diagXTX <<- diag(XTX)
XTy <<- t(original.data$X) %*% diag(weights) %*% original.data$y
beta1.bootstrap.map = c(beta1.bootstrap.map,
main.loop()$beta.posterior$mu[1])
}
return( c(
quantile(beta1.bootstrap.map, (1 - confidence)/2),
quantile(beta1.bootstrap.map, (1 + confidence)/2)
))
}
covered = 0
for(i in 1:n.experiments){
if(i %% 10 == 0) print(i)
vwlb.cs = get.beta1.vwlb.cs(0.95)
print(vwlb.cs)
if(
(vwlb.cs[1] < beta[1])&
(vwlb.cs[2] > beta[1])
) covered = covered + 1
}
n.experiments = 500
covered = 0
for(i in 1:n.experiments){
if(i %% 10 == 0) print(i)
vwlb.cs = get.beta1.vwlb.cs(0.95)
if(
(vwlb.cs[1] < beta[1])&
(vwlb.cs[2] > beta[1])
) covered = covered + 1
}
