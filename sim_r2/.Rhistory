a
q()
setwd("~/Projects/vi_bootstrap_simulation/sim_r2")
sqrt(20)
sqrt(30)
pnrom(-5.47)
pnorm(-5.47)
pnorm(-10/5.47)
pnorm(-10/sqrt(40))
pnorm(-10/sqrt(30))
pnorm(-10/sqrt(20))
pnorm(-10/sqrt(10))
source("point_estimate.R")
n.experiments = 100
n.b.samples = 500
original.data = data
get.beta1.vwlb.cs = function(confidence){
beta1.bootstrap.map = numeric(0)
for(i in 1:n.b.samples){
weights = gen.weights()
data.X <<- diag(sqrt(weights)) %*% original.data$X
data.y <<- diag(sqrt(weights)) %*% original.data$y
XTX <<- t(original.data$X) %*% diag(weights) %*% original.data$X
diagXTX <<- diag(XTX)
XTy <<- t(original.data$X) %*% diag(weights) %*% original.data$y
beta1.bootstrap.map = c(beta1.bootstrap.map,
main.loop()$beta.posterior$mu[1])
}
return( c(
quantile(beta1.bootstrap.map, (1 - confidence)/2),
quantile(beta1.bootstrap.map, (1 + confidence)/2)
))
# return(beta1.bootstrap.map)
}
covered = 0
for(i in 1:n.experiments){
original.data <<- gen.everything()
if(i %% 10 == 0) print(i)
vwlb.cs = get.beta1.vwlb.cs(0.95)
# print(vwlb.cs[1]); print(vwlb.cs[2])
if(
(vwlb.cs[1] < beta[1])&
(vwlb.cs[2] > beta[1])
) covered = covered + 1
}
beta.1.hat = scan()
beta.2.hat = scan()
data.X
data.X %*% beta.1.hat - data.X %*% beta.2.hat
# main loop
main.loop = function(o){
beta.posterior = init.beta.posterior()
global.posterior = init.global.posterior()
new_entropy = rep(0, n.pars)
active.set = rep(TRUE, n.pars)
inv.A = solve(
XTX %*% diag(beta.posterior$phi) + diag(n.pars)/nu1
)
D = numeric(n.pars)
B = XTX - diag(diagXTX)
n.iter = 0
repeat{
n.iter = n.iter + 1
entropy = new_entropy
D = - (beta.posterior$phi)
beta.posterior = cavi.estimate(beta.posterior, global.posterior, inv.A, active.set)
global.posterior = em.estimate(beta.posterior, global.posterior)
D = D + (beta.posterior$phi)
# exclude probabilities close to 0 or 1 from iteration
active.set = ((beta.posterior$phi > prob.threshold) &
(beta.posterior$phi < 1 - prob.threshold))
if(sum(active.set) == 0) break
# inv.A = update.A(inv.A, active.set, B, D)
inv.A = update.A.slow(beta.posterior)
new_entropy = cal.entropy(beta.posterior$phi, active.set)
print(beta.posterior.mu)
if(max(abs(new_entropy - entropy)) < epsilon) break
}
return(list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
))
}
main.loop()
# main loop
main.loop = function(o){
beta.posterior = init.beta.posterior()
global.posterior = init.global.posterior()
new_entropy = rep(0, n.pars)
active.set = rep(TRUE, n.pars)
inv.A = solve(
XTX %*% diag(beta.posterior$phi) + diag(n.pars)/nu1
)
D = numeric(n.pars)
B = XTX - diag(diagXTX)
n.iter = 0
repeat{
n.iter = n.iter + 1
entropy = new_entropy
D = - (beta.posterior$phi)
beta.posterior = cavi.estimate(beta.posterior, global.posterior, inv.A, active.set)
global.posterior = em.estimate(beta.posterior, global.posterior)
D = D + (beta.posterior$phi)
# exclude probabilities close to 0 or 1 from iteration
active.set = ((beta.posterior$phi > prob.threshold) &
(beta.posterior$phi < 1 - prob.threshold))
if(sum(active.set) == 0) break
# inv.A = update.A(inv.A, active.set, B, D)
inv.A = update.A.slow(beta.posterior)
new_entropy = cal.entropy(beta.posterior$phi, active.set)
print(beta.posterior$mu)
if(max(abs(new_entropy - entropy)) < epsilon) break
}
return(list(
beta.posterior = beta.posterior,
global.posterior = global.posterior
))
}
main.loop()
beta.1.hat = scan()
beta.2.hat = scan()
data$X %*% beta.1.hat - data$X %*% beta.2.hat
data$y
a = scan()
min(a)
max(a)
a
a = read.csv("b_samples", sep = " ")
a
a = read.csv("b_samples", sep = " ", head = F)
a
str()
str(a)
a = as.numeric(a)
a
a[1001] = NULL
a = a[1:1000]
var(a)
rm(a)
